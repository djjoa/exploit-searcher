import requests 
from bs4 import BeautifulSoup
import argparse
from termcolor import colored 
import json
import re 
import sys 
# from drivers.export_drivers import init_webdriver
# from selenium.webdriver.common.keys import Keys
# from selenium.webdriver.common.by import By


# 12-18 Start time : 10:30 
# v1.3
parser = argparse.ArgumentParser()
parser.add_argument("-v", "--verbose",action="store_true", 
                help="\tadd verbosity")

parser.add_argument("-s", "--search", type=str,
                help="\tthe search term to query all databases for (exploit, vulnerability, CVE, technology, framework)",
                required=True)

parser.add_argument("-e", "--engine", nargs='+', choices=['rapid7', 'packetstorm', 'cve', 'nvd'], 
                help="engines to use in query; defaults to ALL when not specified. values must be SPACE seperated (not comma).") 

parser.add_argument("-c", "--cve", type=str,
                help="\tCVE ID to refine search")

parser.add_argument("-q", "--quiet", action="store_true",
                help="\tdon't print the banner when running")

args = parser.parse_args()


SEARCHTERM = args.search # for running with command line
CVE_ID = args.cve
ENGINES = args.engine

# PROD : uncomment the above to pass command line options to the script; removed for testing purposes
#SEARCHTERM='smb'


interesting = ['root', 'code execution', 'exploit', 'command','execute','malicious','payload',
                'remote','code','execution','arbitrary','information','leak', 'vulnerability', 'unrestricted', 'remotely']

def title_banner():
    title="""
      📄📄📄📄📄📄📄📄
      📄  ___      __        __    ___      __   ___       __   __        ___  __  
      📄 |__  \_/ |__) |    /  \ |  |  🎯  /__` |__   /\  |__) /  ` |__| |__  |__)
      📄 |___ / \ |    |___ \__/ |  |  🎯  .__/ |___ /~~\ |  \ \__, |  | |___ |  \ 
      📄
      📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄📄
        """
    print(title)
    

def banner(title):
    center = str(title).center(20)
    h1 = colored('◄✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸►◄✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸►' , 'blue')
    h2 = colored(f'◄✸✸✸✸✸{center}✸✸✸✸✸►' , 'blue') * 2 
    h3 = colored('◄✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸►◄✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸✸►' , 'blue')
    print(f"{h1}\n{h2}\n{h3}")
    print()

def resultify(key_string, value_string, color='yellow',end=False): # end = set the end rather than the text color for the key
    if end == True: 
        print(f"{colored(key_string, 'yellow')}: {colored(value_string, color)}")
        return
    print(f"{colored(key_string, color)}: {value_string}")

def query_packetstorm(CVE_ID=None): # bugg with idx+1 [x]TODO 
    banner('Packet Storm')
    
    url = f"https://packetstormsecurity.com/search/?q={SEARCHTERM}"
    page = requests.get(url)
    text = page.text
    base_url = 'https://packetstormsecurity.com'
    # parse number of "Page y of y"
    n_pages = list(set(re.findall(r'href="/search/files/page(\d)/\?q=.*?"',text))) #grab 1,2,3,x for pagination
    n_pages_len = len(n_pages)

    # pagination link examples
    # url = f"https://packetstormsecurity.com/search/page1/?q={SEARCHTERM}"
    # https://packetstormsecurity.com/search/files/page3/?q=shellshock
    all_page_urls = [f"https://packetstormsecurity.com/search/files/page{i}/?q={SEARCHTERM}" for i in range(1,n_pages_len+1)] # works

    
    for link in all_page_urls: #loop around pagination
        # set up BS4 object 
        url = link
        page = requests.get(url)
        soup = BeautifulSoup(page.content, 'html.parser')

        div_frame = soup.find('div', {'id':'m'})
        exploit_frames = div_frame.find_all('dl')#boxes containing exploit name, author, tags, date posted, and advisories
        

        for frame in exploit_frames: 
            #TODO: count = 0 if count is less than number of exploits passed ... 
            exploit_link = frame.find('dt').a['href'] 
            exploit_title = frame.find('dt').a.text 
            exploit_date = frame.find('dd', class_='datetime').a.text
            exploit_description = frame.find('dd', class_='detail').p.text
            exploit_tags = ''.join([str(a.text).replace('tags | ','') for a in frame.find_all('dd', class_='tags')]) #string-list 
            exploit_cves = ''.join([str(dd.text).replace('advisories | ','') for dd in frame.find_all('dd', class_='cve') ]) #string-list 
            exploit_systems = ''.join([str(dd.text).replace('systems | ','') for dd in frame.find_all('dd', class_='os') ]) #string-list 

            # Highlight remote command execution 
            compare_interesting = [i.lower() for i in exploit_title.split(' ')] 
            if  any(item in interesting for item in compare_interesting) : 
                exploit_title = colored(exploit_title, 'red')

            # Highlight root, exploit, RCE in tags 
            split_tags = [t.strip() for t in exploit_tags.split(',')]
            if any(item in interesting for item in split_tags): 
                exploit_tags = colored(exploit_tags, 'red')

            # Colorize certain trigger words on exploit description 
            exploit_description = exploit_description.split(' ')
            colored_description = []
            for word in exploit_description: 
                # if there is a juicy word highlight it red in summary output
                if word in interesting: 
                    colored_description.append(colored(word,'red'))
                else: 
                    colored_description.append(word)
            #reassign the cve description
            exploit_description = ' '.join(colored_description)


            resultify('TITLE', exploit_title)
            resultify('SUMMARY', exploit_description)
            resultify('DATE', exploit_date)
            if exploit_cves: 
                resultify('CVE', exploit_cves)
            if exploit_systems: 
                resultify('SYSTEMS', exploit_systems)
            resultify('TAGS', exploit_tags)     
            resultify('URL', f'{base_url+exploit_link}', 'blue', end=True)
            print() # add space between exploit outputs 
        

    
    
    
    
    # url = f"https://packetstormsecurity.com/search/?q={SEARCHTERM}"
    # packet_storm_page = requests.get(url)
    # soup = BeautifulSoup(packet_storm_page.content, 'html.parser') 
    # #exploit_results = soup.find_all('dl', class_='file')
    
    # titles = [str(a.text) for a in soup.find_all('a', class_='ico text-plain')]
    # ref_links = [f"https://packetstormsecurity.com{a['href']}" for a in soup.find_all('a', class_='ico text-plain')]
    # summaries = [str(dd.text) for dd in soup.find_all('dd', class_='detail') ]
    # cve_ids = [str(dd.text).replace('advisories | ','') for dd in soup.find_all('dd', class_='cve') ]
    # compatable_systems = [str(dd.text).replace('systems | ','') for dd in soup.find_all('dd', class_='os') ]
    # publish_dates = [str(dd.text).replace('Posted ','') for dd in soup.find_all('dd', class_='datetime') ] 
    # tags = [str(dd.text).replace('tags | ','') for dd in soup.find_all('dd', class_='tags') ] 
  
    # banner('Packet Storm')
    # for i in range(0, len(titles)-1): 
    #     #interesting = ['root', 'remote', 'code execution', 'exploit', 'command']
    #     tag = tags[i]
    #     summary = summaries[i]
    #     title = titles[i]

    #     # Highlight remote command execution 
    #     compare_interesting = [i.lower() for i in title.split(' ')] 
    #     if  any(item in interesting for item in compare_interesting) : 
    #         title = colored(title, 'red')

    #     # Highlight root, exploit, RCE in tags 
    #     split_tags = [t.strip() for t in tag.split(',')]
    #     if any(item in interesting for item in split_tags): 
    #         tag = colored(tag, 'red')

    #     resultify('TITLE', title)
    #     resultify('URL', ref_links[i])
    #     resultify('SUMMARY', summary)
    #     resultify('DATE', publish_dates[i])
    #     resultify('CVE', cve_ids[i])
    #     resultify('SYSTEMS', compatable_systems[i])
    #     resultify('TAGS', tag)
        

        # print(f"{colored('TITLE','yellow')}: {title}")
        # print(f"{colored('URL','yellow')}: {ref_links[i]}")
        # print(f"{colored('SUMMARY','yellow')}: {summary}") 
        # print(f"{colored('DATE','yellow')}: {publish_dates[i]}")
        # print(f"{colored('CVE','yellow')}: {cve_ids[i]}")
        # print(f"{colored('SYSTEMS','yellow')}: {compatable_systems[i]}")
        # print(f"{colored('TAGS','yellow')}: {tag}")
        print()         

def query_nvd(CVE_ID=None):
     
    # Dev help https://nvd.nist.gov/developers/vulnerabilities
    # other people doing the same thing https://linuxtut.com/en/97e385ed0a78dc28534f/
    ### 11 Results (grabs the most results) 
    banner('NVD Results')
    
    nvd_url = f'https://services.nvd.nist.gov/rest/json/cves/1.0?apiKey=857af2a5-d596-4593-a3a6-afda6cf9ba40&resultsPerPage=100&keyword={SEARCHTERM}' 
    cves = requests.get(nvd_url)
    json_cves = json.loads(cves.text)

    vulns = json_cves['result']['CVE_Items']
    for  vuln in vulns:
        try: 
            cve_id = vuln['cve']['CVE_data_meta']['ID'] #"ID": "CVE-2021-44224",
        except IndexError: 
            print("NO CVE FOUND")
        #import pdb ; pdb.set_trace()
        try: 
            cve_title = vuln['cve']['references']['reference_data'][0]['name'] # link or title could be here 
        except IndexError: 
            print("NO TITLE FOUND")
        try: 
            cve_reflink = vuln['cve']['references']['reference_data'][0]['url'] # url is always here
        except IndexError: 
            print("NO REFERENCE FOUND")
        try: 
            cve_description = vuln['cve']['description']['description_data'][0]['value']
        except IndexError: 
            print("NO DESCRIPTION FOUND")
        #update these for more colored output in the summary 
        
        cve_description_split = cve_description.split(' ')
        colored_description = []
        for word in cve_description_split: 
            # if there is a juicy word highlight it red in summary output
            if word in interesting: 
                colored_description.append(colored(word,'red'))
            else: 
                colored_description.append(word)
        #reassign the cve description
        cve_description = ' '.join(colored_description)
        
        if 'baseMetricV3' in vuln['impact']:
            v3score = vuln['impact']['baseMetricV3']['cvssV3']['baseScore'] # CRIT|HIGH|MED|LOW
            v3severity = vuln['impact']['baseMetricV3']['cvssV3']['baseSeverity'] # CRIT|HIGH|MED|LOW
            if v3severity == 'HIGH' or v3severity == 'CRITICAL': 
                v3severity = colored(v3severity, 'red')
                v3score = colored(v3score, 'red')
        else : 
            v3score = None
            v3severity = None
        
        if 'baseMetricV2' in vuln['impact']:
            v2score = vuln['impact']['baseMetricV2']['cvssV2']['baseScore'] # HIGH|MED|LOW
            v2severity = vuln['impact']['baseMetricV2']['severity'] # HIGH|MED|LOW
            
            if v2severity == 'HIGH': # set both to red 
                v2severity = colored(v2severity, 'red')
                v2score = colored(v2score, 'red')
        else: 
            v2score = None
            v2severity = None
        
        # TODO RESULTIFY THIS

        if str(cve_title).strip()[0:4] != 'http': 
            print(f"{colored('TITLE','yellow')}: {cve_title}")
        print(f"{colored('CSSV2','yellow')}: {v2score}:{v2severity} | {colored('CSSV3','yellow')}: {v3score}:{v3severity} | {colored('CVE','yellow')}: {colored(cve_id,'yellow')}")
        print(f"{colored('SUMMARY','yellow')}: {cve_description}") 
        print(f"{colored('REFERENCE','yellow')}: {colored(cve_reflink,'blue')}") 

        print()  
        ### 
        # addOns=dictionaryCpes 
        # apiKey optional
        # cpeMatchString optional
        # cvssV2Severity=HIGH|MEDIUM|LOW
        # cvssV3Severity=CRITICAL|HIGH|MEDIUM|LOW
        # isExactMatch=true optional
        # keyword= found in the vulnerability description or reference links. 

def query_rapid7(CVE_ID=None): #TODO 
    banner('Rapid7')
    pass 

def query_cve(CVE_ID=None): 
    banner('CVE Details')
    pass 

def query_edb(): # abandoned for now due to the website not rendering exploits over http. 
                # exploit results are only rendered in the browser making scraping impossible. 

    headers={
    'Host': 'www.exploit-db.com',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:95.0) Gecko/20100101 Firefox/95.0',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive'} 
    # website advanced searc parmeters https://www.exploit-db.com/search?
    # q=TITLE
    # &cve=1111-1111
    # &type=remote
    # &platform=windows
    # &text=EXPLOIT_CONTENT
    # &port=66
    # &verified=true
    # &nomsf=true

    # https://www.exploit-db.com/search?type=remote&platform=windows&port=445 
        # returns remote windows exploits on port 445 with no provided title or CVE
    banner('Exploit Database')
    EDB_TYPES=["dos","local","remote","shellcode","papers","webapps"]
    
    EDB_PLATFORMS=["aix","alpha","android","arm","ashx","asp","aspx",
                   "atheos","beos","bsd","bsdi_x86","bsd_ppc",
                   "bsd_x86","cfm","cgi","ezine","freebsd","freebsd_x86",
                   "freebsd_x86","generator","hardware","hp","immunix",
                   "ios","irix","java","json","jsp","linux","linux_crisv32",
                   "linux_mips","linux_ppc","linux_sparc","linux_x86",
                   "linux_x86","lua","macos","magazine","minix",
                   "multiple","netbsd_x86","netware","nodejs",
                   "novell","openbsd","openbsd_x86","osx","osx_ppc",
                   "palm_os","perl","php","plan9","python","python2",
                   "python3","qnx","ruby","sco","sco_x86","solaris",
                   "solaris_mips","solaris_sparc","solaris_x86","superh_sh4",
                   "system_z","tru64","ultrix","unix","unixware","vxworks",
                   "watchos","windows","windows_x86","windows_x86"]
    
    EDB_TAGS=["Authentication Bypass / Credentials Bypass (AB/CB)",
              "Buffer Overflow","Bug Report","Client Side","Code Injection",
              "Command Injection","Console","Cross-Site Request Forgery (CSRF)",
              "Cross-Site Scripting (XSS)","Denial of Service (DoS)",
              "Deserialization","File Inclusion (LFI/RFI)","Heap Overflow",
              "Integer Overflow","Local","Malware","Metasploit Framework (MSF)",
              "NULL Pointer Dereference","Object Injection","Out Of Bounds",
              "Pwn2Own","Race Condition","Remote","Server-Side Request Forgery (SSRF)",
              "SQL Injection (SQLi)","Traversal","Type Confusion","Use After Free (UAF)",
              "WordPress Core","WordPress Plugin","XML External Entity (XXE)"]
    
    #url = f"https://www.exploit-db.com/search?q={SEARCHTERM}"
    #page = requests.get(url, headers=headers)
    #soup = BeautifulSoup(page.content, 'html.parser') 
    #exploit_table = soup.find('table', {'id':'exploits-table'})
    #exploit_table = soup.find_all('tr', class_='odd')
      
    # TODO lets try using selenium to grab the exploits. 
    
    # # TESTING selenium (scrapping this idea)
    # driver = init_webdriver()
    # driver.get(f"https://www.exploit-db.com/search?q={SEARCHTERM}")
    # test = driver.find_elements(By.ID, 'exploits-table')
    # test = driver.find_elements(By.ID, 'exploits-table')
    # #exp_last = driver.find_elements(By.CLASS_NAME, 'odd')
    # exp_block = driver.find_elements_by_xpath('//tr[@class="even"') 
    # for i in exp_block: 
    #     print(i)

    # driver.close() 

def main(): 
    
    # pass the cve-id somewhere in here
    
    # Dont print banner
    if not args.quiet: 
        title_banner()

    # Engines 
    if ENGINES: # pass the list of differnt engines to be parsed
        
        if 'rapid7' in ENGINES: 
            query_rapid7() 
        if 'packetstorm' in ENGINES: 
            query_packetstorm() 
        if 'cve' in ENGINES: 
            query_cve()
        if 'nvd' in ENGINES: 
            query_nvd()
            quit()

    # Default  (run everything)
            
    query_rapid7() 
    query_packetstorm() 
    query_cve()
    query_nvd()
    quit()


    # TODO / ON HOLD  
    #query_edb() 

    # ### Rapid7
    # f"https://www.rapid7.com/db/?q={SEARCHTERM}&type="
    # site:www.rapid7.com/db/modules/exploit/* "{SEARCHTERM}"

    # ### CVE Details Section 
    # f"https://www.cvedetails.com/google-search-results.php?q={SEARCHTERM}&sa=Search"

    # if CVE_ID: 
    #     f"https://www.exploit-db.com/search?q={SEARCHTERM}&cve={CVE_ID}"
    #     f"https://www.cvedetails.com/cve-details.php?t=1&cve_id=CVE-{CVE_ID}"


if __name__ == '__main__': 
    main() 
    
