import requests 
from bs4 import BeautifulSoup
import argparse
from termcolor import colored 
import json
import re 
import sys 
# from drivers.export_drivers import init_webdriver
# from selenium.webdriver.common.keys import Keys
# from selenium.webdriver.common.by import By


# 12-18 Start time : 10:30 
# v1.3
parser = argparse.ArgumentParser()
parser.add_argument("-v", "--verbose",action="store_true", 
                help="\tadd verbosity")

parser.add_argument("-s", "--search", type=str,
                help="\tthe search term to query all databases for (exploit, vulnerability, CVE, technology, framework)",
                required=True)

parser.add_argument("-e", "--engine", nargs='+', choices=['rapid7', 'packetstorm', 'cve', 'nvd'], 
                help="engines to use in query; defaults to ALL when not specified. values must be SPACE seperated (not comma).") 

parser.add_argument("-c", "--cve", type=str,
                help="\tCVE ID to refine search")

parser.add_argument("-q", "--quiet", action="store_true",
                help="\tdon't print the banner when running")

args = parser.parse_args()


SEARCHTERM = args.search # for running with command line
CVE_ID = args.cve
ENGINES = args.engine

# PROD : uncomment the above to pass command line options to the script; removed for testing purposes
#SEARCHTERM='smb'


interesting = ['root', 'code execution', 'exploit', 'command','execute','malicious','payload',
                'remote','code','execution','arbitrary','information','leak', 'vulnerability', 'unrestricted', 'remotely']

def title_banner():
    title="""
      游늯游늯游늯游늯游늯游늯游늯游늯
      游늯  ___      __        __    ___      __   ___       __   __        ___  __  
      游늯 |__  \_/ |__) |    /  \ |  |  游꿢  /__` |__   /\  |__) /  ` |__| |__  |__)
      游늯 |___ / \ |    |___ \__/ |  |  游꿢  .__/ |___ /~~\ |  \ \__, |  | |___ |  \ 
      游늯
      游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯游늯
        """
    print(title)
    

def banner(title):
    center = str(title).center(20)
    h1 = colored('餃九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊郊쥑듻九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊郊' , 'blue')
    h2 = colored(f'餃九적럊九적럊九잩center}九적럊九적럊九적뒄' , 'blue') * 2 
    h3 = colored('餃九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊郊쥑듻九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊九적럊郊' , 'blue')
    print(f"{h1}\n{h2}\n{h3}")
    print()

def resultify(key_string, value_string, color='yellow',end=False): # end = set the end rather than the text color for the key
    if end == True: 
        print(f"{colored(key_string, 'yellow')}: {colored(value_string, color)}")
        return
    print(f"{colored(key_string, color)}: {value_string}")

def query_packetstorm(CVE_ID=None): # bugg with idx+1 [x]TODO 
    banner('Packet Storm')
    
    url = f"https://packetstormsecurity.com/search/?q={SEARCHTERM}"
    page = requests.get(url)
    text = page.text
    base_url = 'https://packetstormsecurity.com'
    # parse number of "Page y of y"
    n_pages = list(set(re.findall(r'href="/search/files/page(\d)/\?q=.*?"',text))) #grab 1,2,3,x for pagination
    n_pages_len = len(n_pages)

    # pagination link examples
    # url = f"https://packetstormsecurity.com/search/page1/?q={SEARCHTERM}"
    # https://packetstormsecurity.com/search/files/page3/?q=shellshock
    all_page_urls = [f"https://packetstormsecurity.com/search/files/page{i}/?q={SEARCHTERM}" for i in range(1,n_pages_len+1)] # works

    
    for link in all_page_urls: #loop around pagination
        # set up BS4 object 
        url = link
        page = requests.get(url)
        soup = BeautifulSoup(page.content, 'html.parser')

        div_frame = soup.find('div', {'id':'m'})
        exploit_frames = div_frame.find_all('dl')#boxes containing exploit name, author, tags, date posted, and advisories
        

        for frame in exploit_frames: 
            #TODO: count = 0 if count is less than number of exploits passed ... 
            exploit_link = frame.find('dt').a['href'] 
            exploit_title = frame.find('dt').a.text 
            exploit_date = frame.find('dd', class_='datetime').a.text
            exploit_description = frame.find('dd', class_='detail').p.text
            exploit_tags = ''.join([str(a.text).replace('tags | ','') for a in frame.find_all('dd', class_='tags')]) #string-list 
            exploit_cves = ''.join([str(dd.text).replace('advisories | ','') for dd in frame.find_all('dd', class_='cve') ]) #string-list 
            exploit_systems = ''.join([str(dd.text).replace('systems | ','') for dd in frame.find_all('dd', class_='os') ]) #string-list 

            # Highlight remote command execution 
            compare_interesting = [i.lower() for i in exploit_title.split(' ')] 
            if  any(item in interesting for item in compare_interesting) : 
                exploit_title = colored(exploit_title, 'red')

            # Highlight root, exploit, RCE in tags 
            split_tags = [t.strip() for t in exploit_tags.split(',')]
            if any(item in interesting for item in split_tags): 
                exploit_tags = colored(exploit_tags, 'red')

            # Colorize certain trigger words on exploit description 
            exploit_description = exploit_description.split(' ')
            colored_description = []
            for word in exploit_description: 
                # if there is a juicy word highlight it red in summary output
                if word in interesting: 
                    colored_description.append(colored(word,'red'))
                else: 
                    colored_description.append(word)
            #reassign the cve description
            exploit_description = ' '.join(colored_description)


            resultify('TITLE', exploit_title)
            resultify('SUMMARY', exploit_description)
            resultify('DATE', exploit_date)
            if exploit_cves: 
                resultify('CVE', exploit_cves)
            if exploit_systems: 
                resultify('SYSTEMS', exploit_systems)
            resultify('TAGS', exploit_tags)     
            resultify('URL', f'{base_url+exploit_link}', 'blue', end=True)
            print() # add space between exploit outputs 
        

    
    
    
    
    # url = f"https://packetstormsecurity.com/search/?q={SEARCHTERM}"
    # packet_storm_page = requests.get(url)
    # soup = BeautifulSoup(packet_storm_page.content, 'html.parser') 
    # #exploit_results = soup.find_all('dl', class_='file')
    
    # titles = [str(a.text) for a in soup.find_all('a', class_='ico text-plain')]
    # ref_links = [f"https://packetstormsecurity.com{a['href']}" for a in soup.find_all('a', class_='ico text-plain')]
    # summaries = [str(dd.text) for dd in soup.find_all('dd', class_='detail') ]
    # cve_ids = [str(dd.text).replace('advisories | ','') for dd in soup.find_all('dd', class_='cve') ]
    # compatable_systems = [str(dd.text).replace('systems | ','') for dd in soup.find_all('dd', class_='os') ]
    # publish_dates = [str(dd.text).replace('Posted ','') for dd in soup.find_all('dd', class_='datetime') ] 
    # tags = [str(dd.text).replace('tags | ','') for dd in soup.find_all('dd', class_='tags') ] 
  
    # banner('Packet Storm')
    # for i in range(0, len(titles)-1): 
    #     #interesting = ['root', 'remote', 'code execution', 'exploit', 'command']
    #     tag = tags[i]
    #     summary = summaries[i]
    #     title = titles[i]

    #     # Highlight remote command execution 
    #     compare_interesting = [i.lower() for i in title.split(' ')] 
    #     if  any(item in interesting for item in compare_interesting) : 
    #         title = colored(title, 'red')

    #     # Highlight root, exploit, RCE in tags 
    #     split_tags = [t.strip() for t in tag.split(',')]
    #     if any(item in interesting for item in split_tags): 
    #         tag = colored(tag, 'red')

    #     resultify('TITLE', title)
    #     resultify('URL', ref_links[i])
    #     resultify('SUMMARY', summary)
    #     resultify('DATE', publish_dates[i])
    #     resultify('CVE', cve_ids[i])
    #     resultify('SYSTEMS', compatable_systems[i])
    #     resultify('TAGS', tag)
        

        # print(f"{colored('TITLE','yellow')}: {title}")
        # print(f"{colored('URL','yellow')}: {ref_links[i]}")
        # print(f"{colored('SUMMARY','yellow')}: {summary}") 
        # print(f"{colored('DATE','yellow')}: {publish_dates[i]}")
        # print(f"{colored('CVE','yellow')}: {cve_ids[i]}")
        # print(f"{colored('SYSTEMS','yellow')}: {compatable_systems[i]}")
        # print(f"{colored('TAGS','yellow')}: {tag}")
        print()         

def query_nvd(CVE_ID=None):
     
    # Dev help https://nvd.nist.gov/developers/vulnerabilities
    # other people doing the same thing https://linuxtut.com/en/97e385ed0a78dc28534f/
    ### 11 Results (grabs the most results) 
    banner('NVD Results')
    
    nvd_url = f'https://services.nvd.nist.gov/rest/json/cves/1.0?apiKey=857af2a5-d596-4593-a3a6-afda6cf9ba40&resultsPerPage=100&keyword={SEARCHTERM}' 
    cves = requests.get(nvd_url)
    json_cves = json.loads(cves.text)

    vulns = json_cves['result']['CVE_Items']
    for  vuln in vulns:
        try: 
            cve_id = vuln['cve']['CVE_data_meta']['ID'] #"ID": "CVE-2021-44224",
        except IndexError: 
            print("NO CVE FOUND")
        #import pdb ; pdb.set_trace()
        try: 
            cve_title = vuln['cve']['references']['reference_data'][0]['name'] # link or title could be here 
        except IndexError: 
            print("NO TITLE FOUND")
        try: 
            cve_reflink = vuln['cve']['references']['reference_data'][0]['url'] # url is always here
        except IndexError: 
            print("NO REFERENCE FOUND")
        try: 
            cve_description = vuln['cve']['description']['description_data'][0]['value']
        except IndexError: 
            print("NO DESCRIPTION FOUND")
        #update these for more colored output in the summary 
        
        cve_description_split = cve_description.split(' ')
        colored_description = []
        for word in cve_description_split: 
            # if there is a juicy word highlight it red in summary output
            if word in interesting: 
                colored_description.append(colored(word,'red'))
            else: 
                colored_description.append(word)
        #reassign the cve description
        cve_description = ' '.join(colored_description)
        
        if 'baseMetricV3' in vuln['impact']:
            v3score = vuln['impact']['baseMetricV3']['cvssV3']['baseScore'] # CRIT|HIGH|MED|LOW
            v3severity = vuln['impact']['baseMetricV3']['cvssV3']['baseSeverity'] # CRIT|HIGH|MED|LOW
            if v3severity == 'HIGH' or v3severity == 'CRITICAL': 
                v3severity = colored(v3severity, 'red')
                v3score = colored(v3score, 'red')
        else : 
            v3score = None
            v3severity = None
        
        if 'baseMetricV2' in vuln['impact']:
            v2score = vuln['impact']['baseMetricV2']['cvssV2']['baseScore'] # HIGH|MED|LOW
            v2severity = vuln['impact']['baseMetricV2']['severity'] # HIGH|MED|LOW
            
            if v2severity == 'HIGH': # set both to red 
                v2severity = colored(v2severity, 'red')
                v2score = colored(v2score, 'red')
        else: 
            v2score = None
            v2severity = None
        
        # TODO RESULTIFY THIS

        if str(cve_title).strip()[0:4] != 'http': 
            print(f"{colored('TITLE','yellow')}: {cve_title}")
        print(f"{colored('CSSV2','yellow')}: {v2score}:{v2severity} | {colored('CSSV3','yellow')}: {v3score}:{v3severity} | {colored('CVE','yellow')}: {colored(cve_id,'yellow')}")
        print(f"{colored('SUMMARY','yellow')}: {cve_description}") 
        print(f"{colored('REFERENCE','yellow')}: {colored(cve_reflink,'blue')}") 

        print()  
        ### 
        # addOns=dictionaryCpes 
        # apiKey optional
        # cpeMatchString optional
        # cvssV2Severity=HIGH|MEDIUM|LOW
        # cvssV3Severity=CRITICAL|HIGH|MEDIUM|LOW
        # isExactMatch=true optional
        # keyword= found in the vulnerability description or reference links. 

def query_rapid7(CVE_ID=None): #TODO 
    banner('Rapid7')
    pass 

def query_cve(CVE_ID=None): 
    banner('CVE Details')
    pass 

def query_edb(): # abandoned for now due to the website not rendering exploits over http. 
                # exploit results are only rendered in the browser making scraping impossible. 

    headers={
    'Host': 'www.exploit-db.com',
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:95.0) Gecko/20100101 Firefox/95.0',
    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
    'Accept-Language': 'en-US,en;q=0.5',
    'Accept-Encoding': 'gzip, deflate, br',
    'Connection': 'keep-alive'} 
    # website advanced searc parmeters https://www.exploit-db.com/search?
    # q=TITLE
    # &cve=1111-1111
    # &type=remote
    # &platform=windows
    # &text=EXPLOIT_CONTENT
    # &port=66
    # &verified=true
    # &nomsf=true

    # https://www.exploit-db.com/search?type=remote&platform=windows&port=445 
        # returns remote windows exploits on port 445 with no provided title or CVE
    banner('Exploit Database')
    EDB_TYPES=["dos","local","remote","shellcode","papers","webapps"]
    
    EDB_PLATFORMS=["aix","alpha","android","arm","ashx","asp","aspx",
                   "atheos","beos","bsd","bsdi_x86","bsd_ppc",
                   "bsd_x86","cfm","cgi","ezine","freebsd","freebsd_x86",
                   "freebsd_x86","generator","hardware","hp","immunix",
                   "ios","irix","java","json","jsp","linux","linux_crisv32",
                   "linux_mips","linux_ppc","linux_sparc","linux_x86",
                   "linux_x86","lua","macos","magazine","minix",
                   "multiple","netbsd_x86","netware","nodejs",
                   "novell","openbsd","openbsd_x86","osx","osx_ppc",
                   "palm_os","perl","php","plan9","python","python2",
                   "python3","qnx","ruby","sco","sco_x86","solaris",
                   "solaris_mips","solaris_sparc","solaris_x86","superh_sh4",
                   "system_z","tru64","ultrix","unix","unixware","vxworks",
                   "watchos","windows","windows_x86","windows_x86"]
    
    EDB_TAGS=["Authentication Bypass / Credentials Bypass (AB/CB)",
              "Buffer Overflow","Bug Report","Client Side","Code Injection",
              "Command Injection","Console","Cross-Site Request Forgery (CSRF)",
              "Cross-Site Scripting (XSS)","Denial of Service (DoS)",
              "Deserialization","File Inclusion (LFI/RFI)","Heap Overflow",
              "Integer Overflow","Local","Malware","Metasploit Framework (MSF)",
              "NULL Pointer Dereference","Object Injection","Out Of Bounds",
              "Pwn2Own","Race Condition","Remote","Server-Side Request Forgery (SSRF)",
              "SQL Injection (SQLi)","Traversal","Type Confusion","Use After Free (UAF)",
              "WordPress Core","WordPress Plugin","XML External Entity (XXE)"]
    
    #url = f"https://www.exploit-db.com/search?q={SEARCHTERM}"
    #page = requests.get(url, headers=headers)
    #soup = BeautifulSoup(page.content, 'html.parser') 
    #exploit_table = soup.find('table', {'id':'exploits-table'})
    #exploit_table = soup.find_all('tr', class_='odd')
      
    # TODO lets try using selenium to grab the exploits. 
    
    # # TESTING selenium (scrapping this idea)
    # driver = init_webdriver()
    # driver.get(f"https://www.exploit-db.com/search?q={SEARCHTERM}")
    # test = driver.find_elements(By.ID, 'exploits-table')
    # test = driver.find_elements(By.ID, 'exploits-table')
    # #exp_last = driver.find_elements(By.CLASS_NAME, 'odd')
    # exp_block = driver.find_elements_by_xpath('//tr[@class="even"') 
    # for i in exp_block: 
    #     print(i)

    # driver.close() 

def main(): 
    
    # pass the cve-id somewhere in here
    
    # Dont print banner
    if not args.quiet: 
        title_banner()

    # Engines 
    if ENGINES: # pass the list of differnt engines to be parsed
        
        if 'rapid7' in ENGINES: 
            query_rapid7() 
        if 'packetstorm' in ENGINES: 
            query_packetstorm() 
        if 'cve' in ENGINES: 
            query_cve()
        if 'nvd' in ENGINES: 
            query_nvd()
            quit()

    # Default  (run everything)
            
    query_rapid7() 
    query_packetstorm() 
    query_cve()
    query_nvd()
    quit()


    # TODO / ON HOLD  
    #query_edb() 

    # ### Rapid7
    # f"https://www.rapid7.com/db/?q={SEARCHTERM}&type="
    # site:www.rapid7.com/db/modules/exploit/* "{SEARCHTERM}"

    # ### CVE Details Section 
    # f"https://www.cvedetails.com/google-search-results.php?q={SEARCHTERM}&sa=Search"

    # if CVE_ID: 
    #     f"https://www.exploit-db.com/search?q={SEARCHTERM}&cve={CVE_ID}"
    #     f"https://www.cvedetails.com/cve-details.php?t=1&cve_id=CVE-{CVE_ID}"


if __name__ == '__main__': 
    main() 
    
